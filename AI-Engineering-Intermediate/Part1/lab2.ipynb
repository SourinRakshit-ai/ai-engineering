{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e9e9106",
   "metadata": {},
   "source": [
    "# Prompt Engineering\n",
    "\n",
    "## Just a quick definition\n",
    "\n",
    "Prompt engineering is the process of designing and refining input prompts to guide large language models (LLMs) toward producing accurate, relevant, and useful outputs. It involves crafting clear instructions, providing context, and sometimes including examples to achieve the desired response from the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b60c1b",
   "metadata": {},
   "source": [
    "### Prompt Elements\n",
    "\n",
    "A prompt contains any of the following elements:\n",
    "\n",
    "**Instruction** - a specific task or instruction you want the model to perform\n",
    "\n",
    "**Context** - external information or additional context that can steer the model to better responses\n",
    "\n",
    "**Input Data** - the input or question that we are interested to find a response for\n",
    "\n",
    "**Output Indicator** - the type or format of the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5240aeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from openai import OpenAI\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2b71096",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "# Call OpenAI model response function\n",
    "\n",
    "def get_response(prompt: str, model: str, response_id: Optional[int] = None) -> tuple[str, int]:\n",
    "    response = client.responses.create(\n",
    "        model=model,\n",
    "        previous_response_id=response_id,\n",
    "        input=[{\"role\": \"user\",\"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    return response.output_text, response.id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d817ff0",
   "metadata": {},
   "source": [
    "# Prompting Methods\n",
    "\n",
    "### 1. Zero-shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "552f847d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ede57ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The text falls into the category of **Technology**."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PROMPT = \"\"\"\n",
    "\n",
    "Classify the following text into one of the following categories:\n",
    "1. Technology\n",
    "2. Science\n",
    "3. Art\n",
    "4. History\n",
    "\n",
    "Text: The advancements in quantum computing have the potential to revolutionize the field of cryptography, enabling faster processing and more secure communication methods.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Call the response function\n",
    "response_text, response_id = get_response(PROMPT, MODEL)\n",
    "display(Markdown(response_text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a2efc7",
   "metadata": {},
   "source": [
    "### 2. Few-shot/Multi-shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5991b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Technology"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PROMPT = \"\"\"\n",
    "\n",
    "Classify the following text into one of the following categories:\n",
    "1. Technology\n",
    "2. Science\n",
    "3. Art\n",
    "4. History\n",
    "\n",
    "Text: The advancements in quantum computing have the potential to revolutionize the field of cryptography, enabling faster processing and more secure communication methods.\n",
    "\n",
    "EXAMPLES\n",
    "\n",
    "Q: The invention of the printing press in the 15th century allowed for the mass production of books and the spread of knowledge.\n",
    "Technology\n",
    "\n",
    "Q: The discovery of penicillin in 1928 marked the beginning of modern antibiotics and has saved countless lives.\n",
    "Science\n",
    "\n",
    "Q: The Mona Lisa, painted by Leonardo da Vinci in the 16th century, is one of the most famous works of art in history.\n",
    "Art\n",
    "\n",
    "Q: The fall of the Berlin Wall in 1989 was a significant event in world history, symbolizing the end of the Cold War.\n",
    "History\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Call the response function\n",
    "response_text, response_id = get_response(PROMPT, MODEL)\n",
    "display(Markdown(response_text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd0ccb2",
   "metadata": {},
   "source": [
    "### 3. Chain-of-Thought (CoT) Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "764f385b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Let's break down the scenario step by step:\n",
       "\n",
       "1. After the first hour:\n",
       "   - Train A travels 60 miles\n",
       "   - Train B travels 40 miles\n",
       "   - Distance remaining between the trains = 300 - (60 + 40) = 200 miles\n",
       "\n",
       "2. Starting from the second hour:\n",
       "   - Train A's speed = 60 + 20 = 80 miles per hour\n",
       "   - Train B's speed = 40 - 10 = 30 miles per hour\n",
       "   - Combined speed of the two trains = 80 + 30 = 110 miles per hour\n",
       "\n",
       "3. Time taken for the two trains to meet:\n",
       "   - Time = Distance / Speed\n",
       "   - Time = 200 miles / 110 miles per hour\n",
       "   - Time â‰ˆ 1.82 hours\n",
       "\n",
       "Therefore, the two trains will meet approximately 1.82 hours after their departure."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bad example\n",
    "MODEL = \"gpt-3.5-turbo\"\n",
    "PROMPT = \"\"\"\n",
    "\n",
    "A train leaves City A heading towards City B at 60 miles per hour.\n",
    "At the same time, another train leaves City B heading towards City A at 40 miles per hour.\n",
    "The cities are 300 miles apart. However, after 1 hour, the train from City A increases its \n",
    "speed by 20 miles per hour, and the train from City B decreases its speed by 10 miles per hour. \n",
    "How long after departure will the two trains meet?\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Call the response function\n",
    "response_text, response_id = get_response(PROMPT, MODEL)\n",
    "display(Markdown(response_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd811932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Let's denote the initial speed of the train from City A as \\( A \\) and the initial speed of the train from City B as \\( B \\).\n",
       "\n",
       "1. Initial speeds of the trains:\n",
       "   - Initial speed of the train from City A, \\( A = 60 \\) mph\n",
       "   - Initial speed of the train from City B, \\( B = 40 \\) mph\n",
       "\n",
       "2. After 1 hour:\n",
       "   - Total distance covered by the train from City A in 1 hour: \\( 60 \\) mph * \\( 1 \\) hour = 60 miles\n",
       "   - Total distance covered by the train from City B in 1 hour: \\( 40 \\) mph * \\( 1 \\) hour = 40 miles\n",
       "\n",
       "3. Remaining distance after the first hour: 300 miles - 60 miles - 40 miles = 200 miles\n",
       "\n",
       "4. New speeds after the first hour:\n",
       "   - Speed of the train from City A after the first hour: \\( 60 \\) mph + \\( 20 \\) mph = 80 mph\n",
       "   - Speed of the train from City B after the first hour: \\( 40 \\) mph - \\( 10 \\) mph = 30 mph\n",
       "\n",
       "5. Time taken for the trains to meet after the first hour:\n",
       "   - Combined speed of both trains after the first hour: \\( 80 \\) mph + \\( 30 \\) mph = 110 mph\n",
       "   - Time taken to cover the remaining 200 miles at 110 mph: \\( \\frac{200}{110} \\) hours\n",
       "\n",
       "6. Total time taken for the trains to meet:\n",
       "   - Total time = 1 hour (first hour) + \\( \\frac{200}{110} \\) hours\n",
       "\n",
       "Now, let's calculate the total time taken for the trains to meet:\n",
       "\n",
       "Total time = 1 hour + \\( \\frac{200}{110} \\) hours\n",
       "Total time = 1 hour + \\( \\frac{20}{11} \\) hours\n",
       "Total time = \\( \\frac{11}{11} \\) hours + \\( \\frac{20}{11} \\) hours\n",
       "Total time = \\( \\frac{31}{11} \\) hours\n",
       "\n",
       "Therefore, the trains will meet \\( \\frac{31}{11} \\) hours after departure, which is approximately 2.82 hours or 2 hours and 49 minutes."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL = \"gpt-3.5-turbo\"\n",
    "PROMPT = \"\"\"\n",
    "\n",
    "A train leaves City A heading towards City B at 60 miles per hour.\n",
    "At the same time, another train leaves City B heading towards City A at 40 miles per hour.\n",
    "The cities are 300 miles apart. However, after 1 hour, the train from City A increases its \n",
    "speed by 20 miles per hour, and the train from City B decreases its speed by 10 miles per hour. \n",
    "How long after departure will the two trains meet?\n",
    "\n",
    "Let's solve this problem step by step:\n",
    "1. Identify the speeds of both trains before and after the first hour.\n",
    "2. Calculate the distance covered by both trains in the first hour.\n",
    "3. Determine the remaining distance after the first hour.\n",
    "4. Calculate the new speeds of both trains after the first hour.\n",
    "5. Find out how much time it takes for the trains to meet after the first hour.\n",
    "6. Add up the total time taken for the trains to meet.\n",
    "\n",
    "Show all calculations and reasoning clearly.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Call the response function\n",
    "response_text, response_id = get_response(PROMPT, MODEL)\n",
    "display(Markdown(response_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19aa5d7",
   "metadata": {},
   "source": [
    "# Techniques for better prompts\n",
    "\n",
    "### Technique 1: Write clear and concise instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b05bf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"I need to buy a birthday present for my sister\"\n",
    "\n",
    "# Call the response function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0a0efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"I need to buy a birthday present for my sister. She is 12 years old and is interested in ponies. Reply only with 2 options.\"\n",
    "\n",
    "# Call the response function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9434041a",
   "metadata": {},
   "source": [
    "### Technique 2: Split your task into simpler subtasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17bf448",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"\n",
    "\n",
    "Write an article about the importance of muscle for skeletal health and mobility in old age.\n",
    "\n",
    "Follow these guidelines:\n",
    "- Jot down high-level bullets on the subject\n",
    "- Write a short introduction\n",
    "- Write a detailed section on the importance of muscle for skeletal health\n",
    "- Write a detailed section on the importance of muscle for mobility\n",
    "- Write a conclusion summarizing the key points\n",
    "- Use markdown formatting\n",
    "- Use a friendly and engaging tone\n",
    "- Use simple language that is easy to understand\n",
    "- Use a maximum of 500 words\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f0d03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the response function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93eb81f",
   "metadata": {},
   "source": [
    "### Technique 3: Markdown Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c2dfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"\n",
    "\n",
    "You will be tasked to build a simple application using Python and Flask.\n",
    "\n",
    "You MUST plan effectively, thinking through each step before you write code.\n",
    "\n",
    "I want you to build an app that, upon clicking a button, will generate random Yoda quotes.\n",
    "\n",
    "# Workflow\n",
    "\n",
    "## High-level problem solving strategy\n",
    "1. Deeply understand the user's requirements.\n",
    "2. Break down the requirements into smaller tasks.\n",
    "3. For each task, think through the implementation details.\n",
    "4. Write code for each task, ensuring it works correctly.\n",
    "5. Test the code to ensure it meets the requirements.\n",
    "\n",
    "## Code implementation strategy\n",
    "1. Start with the main application structure.\n",
    "2. Implement the core functionality.\n",
    "3. Add any additional features as needed.\n",
    "\n",
    "## Other notes:\n",
    "1. The app should look sleep and modern\n",
    "2. It should feel snappy\n",
    "3. Do not ask any questions\n",
    "4. Give me the entire code in one file\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ab760e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the response function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5ca2a5",
   "metadata": {},
   "source": [
    "Let's compare with bad prompt engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26719344",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"I want you to build an app that, upon clicking a button, will generate random Yoda quotes. The app should be sleek and modern and snappy. Give me all the code in one python file.\"\n",
    "\n",
    "# Call the response function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a15a39",
   "metadata": {},
   "source": [
    "## Resources\n",
    "- [GPT-4.1 Prompting Guide](https://arxiv.org/pdf/2406.13121)\n",
    "- [Lee et al](https://arxiv.org/pdf/2406.13121) - More complex prompt structures\n",
    "- [Best Practices for Prompt Engineering by OpenAI API](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-the-openai-api)\n",
    "- [Prompt Engineering Repo](https://github.com/dair-ai/Prompt-Engineering-Guide) - A fantastic resource on more advanced prompt engineering tactics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fad314b",
   "metadata": {},
   "source": [
    "## Your Turn: Build an App with LLMs and Good Prompt Engineering\n",
    "\n",
    "Now that you've learned about prompt engineering and seen examples of how prompt quality affects LLM outputs, it's time to put your skills into practice!\n",
    "\n",
    "### Instructions\n",
    "- Think of a simple app or tool you want to build using an LLM (for example: a quiz generator, a text summarizer, a code explainer, a recipe recommender, etc.).\n",
    "- Write a prompt for the LLM that follows the good prompt engineering principles discussed:\n",
    "  - Be clear and specific about the task.\n",
    "  - Provide context and examples if needed.\n",
    "  - Specify the desired output format.\n",
    "  - Break down complex tasks into steps.\n",
    "- Use the provided `get_response` function to interact with the LLM and build your app logic in Python.\n",
    "- Display the results in a user-friendly way (e.g., using Markdown output).\n",
    "\n",
    "---\n",
    "\n",
    "Try to:\n",
    "- Document your approach and prompt design.\n",
    "- Experiment with different prompt styles and see how the output changes.\n",
    "- Share your app and prompt with others for feedback!\n",
    "\n",
    "Add your code to the `AI-Engineering-Intermediate/Part1/community-contributions` folder and open up a PR. All the instructions for uploading your contributions can be found in the [CONTRIBUTING](../../CONTRIBUTING.md) file.\n",
    "\n",
    "**BONUS:** Post about the app that you have built using your chosen LLM and tag the [SuperDataScience Community LinkedIn page](https://www.linkedin.com/showcase/superdatascience-community-projects/) for a chance to have your post shared with the official SDS page (both the community projects page and main [SDS page](https://www.linkedin.com/showcase/superdatascience)) and have your post seen by **everyone** who follows SDS on LinkedIn (~100,000 followers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29d290d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
