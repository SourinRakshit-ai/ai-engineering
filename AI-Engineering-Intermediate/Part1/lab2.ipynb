{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e9e9106",
   "metadata": {},
   "source": [
    "# Prompt Engineering\n",
    "\n",
    "## Just a quick definition\n",
    "\n",
    "Prompt engineering is the process of designing and refining input prompts to guide large language models (LLMs) toward producing accurate, relevant, and useful outputs. It involves crafting clear instructions, providing context, and sometimes including examples to achieve the desired response from the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b60c1b",
   "metadata": {},
   "source": [
    "### Prompt Elements\n",
    "\n",
    "A prompt contains any of the following elements:\n",
    "\n",
    "**Instruction** - a specific task or instruction you want the model to perform\n",
    "\n",
    "**Context** - external information or additional context that can steer the model to better responses\n",
    "\n",
    "**Input Data** - the input or question that we are interested to find a response for\n",
    "\n",
    "**Output Indicator** - the type or format of the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b71096",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def get_response(prompt: str, model: str, response_id: Optional[int] = None) -> tuple[str, int]:\n",
    "    response = client.responses.create(\n",
    "    model=model,\n",
    "    previous_response_id=response_id,\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ]\n",
    "    )\n",
    "\n",
    "    return response.output_text, response.id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d817ff0",
   "metadata": {},
   "source": [
    "### 1. Zero-shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552f847d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ede57ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The text fits into the **Technology** category."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PROMPT = \"\"\"\n",
    "\n",
    "Classify the following text into one of the following categories:\n",
    "1. Technology\n",
    "2. Science\n",
    "3. Art\n",
    "4. History\n",
    "\n",
    "Text: The advancements in quantum computing have the potential to revolutionize the field of cryptography, enabling faster processing and more secure communication methods.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response_text, response_id = get_response(PROMPT, MODEL)\n",
    "display(Markdown(response_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a2efc7",
   "metadata": {},
   "source": [
    "### 2. Few-shot/Multi-shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5991b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "A: Technology"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PROMPT = \"\"\"\n",
    "\n",
    "Classify the following text into one of the following categories:\n",
    "\n",
    "1. Technology\n",
    "2. Science\n",
    "3. Art\n",
    "4. History\n",
    "\n",
    "Text: The advancements in quantum computing have the potential to revolutionize the field of cryptography, enabling faster processing and more secure communication methods.\n",
    "\n",
    "EXAMPLES\n",
    "\n",
    "Q: The invention of the printing press in the 15th century allowed for the mass production of books and the spread of knowledge.\n",
    "A: Technology\n",
    "\n",
    "Q: The discovery of penicillin in 1928 marked the beginning of modern antibiotics and has saved countless lives.\n",
    "A: Science\n",
    "\n",
    "Q: The Mona Lisa, painted by Leonardo da Vinci in the 16th century, is one of the most famous works of art in history.\n",
    "A: Art\n",
    "\n",
    "Q: The fall of the Berlin Wall in 1989 was a significant event in world history, symbolizing the end of the Cold War.\n",
    "A: History\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response_text, response_id = get_response(PROMPT, MODEL)\n",
    "display(Markdown(response_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd0ccb2",
   "metadata": {},
   "source": [
    "### 3. Chain-of-Thought (CoT) Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764f385b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To solve this problem, we can set up equations based on the distances traveled by each train and the time it takes for them to meet.\n",
       "\n",
       "Let x be the time (in hours) it takes for the two trains to meet after their departure.\n",
       "\n",
       "For the train leaving City A:\n",
       "Distance = Speed * Time\n",
       "Distance = 60 * (x+1) (after the first hour, the speed is 60 mph)\n",
       "Distance = 60x + 60\n",
       "\n",
       "For the train leaving City B:\n",
       "Distance = Speed * Time\n",
       "Distance = 40 * (x+1) (after the first hour, the speed is 40 mph)\n",
       "Distance = 40x + 40\n",
       "\n",
       "Since the total distance between the two cities is 300 miles, we can set up the equation:\n",
       "60x + 60 + 40x + 40 = 300\n",
       "\n",
       "Combine like terms:\n",
       "100x + 100 = 300\n",
       "\n",
       "Subtract 100 from both sides:\n",
       "100x = 200\n",
       "\n",
       "Divide by 100:\n",
       "x = 2\n",
       "\n",
       "Therefore, the two trains will meet 2 hours after their departure."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL = \"gpt-3.5-turbo\"\n",
    "PROMPT = \"\"\"\n",
    "\n",
    "A train leaves City A heading towards City B at 60 miles per hour.\n",
    "At the same time, another train leaves City B heading towards City A at 40 miles per hour.\n",
    "The cities are 300 miles apart. However, after 1 hour, the train from City A increases its \n",
    "speed by 20 miles per hour, and the train from City B decreases its speed by 10 miles per hour. \n",
    "How long after departure will the two trains meet?\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response_text, response_id = get_response(PROMPT, MODEL)\n",
    "display(Markdown(response_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2df2e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Let's break down the problem step by step:\n",
       "\n",
       "1. **Initial speeds and distances**: \n",
       "   - Initially, the two trains are approaching each other at a combined speed of 60 mph + 40 mph = 100 mph.\n",
       "   - Therefore, after 1 hour, they would have covered a combined distance of 100 miles (100 mph * 1 hr).\n",
       "\n",
       "2. **Change in speeds**: \n",
       "   - After 1 hour, the train from City A increases its speed to 60 mph + 20 mph = 80 mph.\n",
       "   - At the same time, the train from City B decreases its speed to 40 mph - 10 mph = 30 mph.\n",
       "\n",
       "3. **Relative speed**: \n",
       "   - The relative speed of the two trains now is 80 mph + 30 mph = 110 mph.\n",
       "\n",
       "4. **Time to meet at increased speeds**:\n",
       "   - Now, the combined distance they need to cover is 300 miles - 100 miles = 200 miles (as they've already covered 100 miles in the first hour).\n",
       "   - The time it will take for them to meet at this new relative speed of 110 mph is 200 miles / 110 mph = 1.82 hours.\n",
       "\n",
       "5. **Total time elapsed**:\n",
       "   - The total time elapsed since the departure of the two trains will be 1 hour (initial) + 1.82 hours = 2.82 hours (~2 hours and 49 minutes).\n",
       "\n",
       "Therefore, the two trains will meet approximately 2 hours and 49 minutes after their departure."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PROMPT = \"\"\"\n",
    "\n",
    "A train leaves City A heading towards City B at 60 miles per hour. \n",
    "At the same time, another train leaves City B heading towards City A at 40 miles per hour. \n",
    "The cities are 300 miles apart. However, after 1 hour, the train from City A increases its \n",
    "speed by 20 miles per hour, and the train from City B decreases its speed by 10 miles per hour. \n",
    "How long after departure will the two trains meet?\n",
    "\n",
    "Think about this problem step by step.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response_text, response_id = get_response(PROMPT, MODEL)\n",
    "display(Markdown(response_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19aa5d7",
   "metadata": {},
   "source": [
    "### Technique 1: Write clear and concise instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b05bf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"I need to buy a birthday present for my sister\"\n",
    "\n",
    "response_text, response_id = get_response(PROMPT)\n",
    "display(Markdown(response_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0a0efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"I need to buy a birthday present for my sister. She is 12 years old and is interested in ponies. Reply only with 2 options.\"\n",
    "\n",
    "response_text, response_id = get_response(PROMPT)\n",
    "display(Markdown(response_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9434041a",
   "metadata": {},
   "source": [
    "### Technique 2: Split your task into simpler subtasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17bf448",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"\n",
    "\n",
    "Write an article about the importance of muscle for skeletal health and mobility in old age.\n",
    "\n",
    "Follow these guidelines:\n",
    "- Jot down high-level bullets on the subject\n",
    "- Write a short introduction\n",
    "- Write a detailed section on the importance of muscle for skeletal health\n",
    "- Write a detailed section on the importance of muscle for mobility\n",
    "- Write a conclusion summarizing the key points\n",
    "- Use markdown formatting\n",
    "- Use a friendly and engaging tone\n",
    "- Use simple language that is easy to understand\n",
    "- Use a maximum of 500 words\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f0d03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_text, response_id = get_response(PROMPT)\n",
    "display(Markdown(response_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93eb81f",
   "metadata": {},
   "source": [
    "### Technique 3: Markdown Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c2dfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"\n",
    "\n",
    "You will be tasked to build a simple application using Python and Flask.\n",
    "\n",
    "You MUST plan effectively, thinking through each step before you write code.\n",
    "\n",
    "I want you to build an app that, upon clicking a button, will generate random Yoda quotes.\n",
    "\n",
    "# Workflow\n",
    "\n",
    "## High-level problem solving strategy\n",
    "1. Deeply understand the user's requirements.\n",
    "2. Break down the requirements into smaller tasks.\n",
    "3. For each task, think through the implementation details.\n",
    "4. Write code for each task, ensuring it works correctly.\n",
    "5. Test the code to ensure it meets the requirements.\n",
    "\n",
    "## Code implementation strategy\n",
    "1. Start with the main application structure.\n",
    "2. Implement the core functionality.\n",
    "3. Add any additional features as needed.\n",
    "\n",
    "## Other notes:\n",
    "1. The app should look sleep and modern\n",
    "2. It should feel snappy\n",
    "3. Do not ask any questions\n",
    "4. Give me the entire code in one file\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ab760e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_text, response_id = get_response(PROMPT)\n",
    "display(Markdown(response_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5ca2a5",
   "metadata": {},
   "source": [
    "Let's compare with bad prompt engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26719344",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"I want you to build an app that, upon clicking a button, will generate random Yoda quotes. The app should be sleek and modern and snappy. Give me all the code in one python file.\"\n",
    "\n",
    "response_text, response_id = get_response(PROMPT)\n",
    "display(Markdown(response_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a15a39",
   "metadata": {},
   "source": [
    "## Resources\n",
    "- [GPT-4.1 Prompting Guide](https://arxiv.org/pdf/2406.13121)\n",
    "- [Lee et al](https://arxiv.org/pdf/2406.13121) - More complex prompt structures\n",
    "- [Best Practices for Prompt Engineering by OpenAI API](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-the-openai-api)\n",
    "- [Prompt Engineering Repo](https://github.com/dair-ai/Prompt-Engineering-Guide) - A fantastic resource on more advanced prompt engineering tactics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fad314b",
   "metadata": {},
   "source": [
    "## Your Turn: Build an App with LLMs and Good Prompt Engineering\n",
    "\n",
    "Now that you've learned about prompt engineering and seen examples of how prompt quality affects LLM outputs, it's time to put your skills into practice!\n",
    "\n",
    "### Instructions\n",
    "- Think of a simple app or tool you want to build using an LLM (for example: a quiz generator, a text summarizer, a code explainer, a recipe recommender, etc.).\n",
    "- Write a prompt for the LLM that follows the good prompt engineering principles discussed:\n",
    "  - Be clear and specific about the task.\n",
    "  - Provide context and examples if needed.\n",
    "  - Specify the desired output format.\n",
    "  - Break down complex tasks into steps.\n",
    "- Use the provided `get_response` function to interact with the LLM and build your app logic in Python.\n",
    "- Display the results in a user-friendly way (e.g., using Markdown output).\n",
    "\n",
    "---\n",
    "\n",
    "Try to:\n",
    "- Document your approach and prompt design.\n",
    "- Experiment with different prompt styles and see how the output changes.\n",
    "- Share your app and prompt with others for feedback!\n",
    "\n",
    "Add your code to the `AI-Engineering-Intermediate/Part1/community-contributions` folder and open up a PR. All the instructions for uploading your contributions can be found in the [CONTRIBUTING](../../CONTRIBUTING.md) file.\n",
    "\n",
    "**BONUS:** Post about the app that you have built using your chosen LLM and tag the [SuperDataScience Community LinkedIn page](https://www.linkedin.com/showcase/superdatascience-community-projects/) for a chance to have your post shared with the official SDS page (both the community projects page and main [SDS page](https://www.linkedin.com/showcase/superdatascience)) and have your post seen by **everyone** who follows SDS on LinkedIn (~100,000 followers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29d290d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
